#!/usr/bin/env python
# coding: utf-8

# In our data, a data scientist usually has to deal with a lot of noise and extra useless data, informally known as, junk. As a proficient data scientist, you should know how to filter out and clean your data.

# In[1]:


import pandas as pd
import numpy as np


# In[3]:


df = pd.read_csv('/Users/shrutayyyy_/Desktop/melb_data.csv')
df.head(10)


# Your dataset had too many variables to wrap your head around, or even to print out nicely. How can you pare down this overwhelming amount of data to something you can understand?
# 
# To show you the techniques, we'll start by picking a few variables using our intuition. Later tutorials will show you statistical techniques to automatically prioritize variables.
# 
# Before we can choose variables/columns, it is helpful to see a list of all columns in the dataset. That is done with the columns property of the DataFrame (the bottom line of code below).

# In[5]:


df.columns


# Whew, that is a lot of columns, ain't it? Usually when we study a dataset, we don't need most of the data that is part of it, and for that we need to filter and select the import information that we really actually need.

# You can pull out any variable (or column) with dot-notation. This single column is stored in a Series, which is broadly like a DataFrame with only a single column of data. Here's an example:

# In[6]:


df_price_data = df.Price
df_price_data.head(10)


# We can also build our own DataFrame from the original data which includes few of the columns of the original data.

# We can select multiple columns from a DataFrame by providing a list of column names inside brackets. Remember, each item in that list should be a string (with quotes).

# In[9]:


columns_of_interest = ['Landsize', 'BuildingArea']
two_columns_of_data = df[columns_of_interest]
two_columns_of_data.head(10)


# And here we have the DataFrame we just created. You can see how unclean our data is by the high number of NaN values in it. I hope by now you know how to get rid of them! If not, you can go through the material providedfor day 1.

# Many times for the study of our data, we need to find out various mathematical properties of the data itself like mean, median,standard deviation, etc. Now wait, don't rush to get your calculators to do all the aforementioned calculations! Pandas already has all these nifty little functions inbuilt into it. To find the mathematical properties, we have to use the describe() method.

# In[10]:


two_columns_of_data.describe()


# In[ ]:




